{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KxNXdtkL4oP"
      },
      "source": [
        "# An acoustic analysis of vowel production by L1-Chinese learners of English - Part 3: Statistical Analysis\n",
        "\n",
        "This is an interactive notebook that reproduces the statistical analysis of the talk *An acoustic analysis of vowel production by L1-Chinese learners of English* given November 15, 2024, at the University of Hamburg by Martin Schweinberger.\n",
        "\n",
        "\n",
        "\n",
        "## Preparation\n",
        "\n",
        "\n",
        "load packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mhehZEtL4oS"
      },
      "outputs": [],
      "source": [
        "library(tidyverse)\n",
        "library(here)\n",
        "library(adehabitatHR)\n",
        "library(lme4)\n",
        "library(sjPlot)\n",
        "library(report)\n",
        "library(flextable)\n",
        "library(cowplot)\n",
        "library(randomForest)\n",
        "library(rms)\n",
        "library(caret)\n",
        "library(Hmisc)\n",
        "library(quanteda)\n",
        "#library(glmulti) # do not use this package in the interactive notebook!\n",
        "# it accesses Java and thus crashes the kernel\n",
        "library(partykit)\n",
        "library(ggparty)\n",
        "library(hunspell)\n",
        "library(janitor)\n",
        "library(viridis)\n",
        "library(TMB)\n",
        "library(MuMIn)\n",
        "library(car)\n",
        "# set options\n",
        "options(stringsAsFactors = F)\n",
        "options(scipen = 999)\n",
        "options(max.print=10000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdk51ISnL4oV"
      },
      "source": [
        "## Load data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPK1YlTNL4oV"
      },
      "outputs": [],
      "source": [
        "# load .rda data\n",
        "cdat  <- base::readRDS(file = here::here(\"cleandat.rda\")) %>%\n",
        "  dplyr::filter(vowel != \"ʌ\") %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::relocate(duration, .after = F2) %>%\n",
        "  dplyr::relocate(file, .after = Age)\n",
        "# inspect\n",
        "str(cdat); head(cdat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63r4b-BAL4oX"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxeKmEh9L4oY"
      },
      "outputs": [],
      "source": [
        "table(cdat$vowel, cdat$word)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq87aUThL4oZ"
      },
      "source": [
        "## Reduce data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsyCbSJUL4oa"
      },
      "outputs": [],
      "source": [
        "bdat <- cdat %>%\n",
        "  dplyr::mutate(label = stringr::str_remove_all(label, \":\"),\n",
        "                gender = ifelse(gender == \"f\", \"female\", gender),\n",
        "                gender = ifelse(gender == \"m\", \"male\", gender),\n",
        "                tvariety = ifelse(tvariety == \"us\", \"AmE\", tvariety),\n",
        "                tvariety = ifelse(tvariety == \"gb\", \"BrE\", tvariety)) %>%\n",
        "  droplevels(.)  %>%\n",
        "  dplyr::rename(Vowel = label,\n",
        "                Word = word,\n",
        "                TargetVariety = tvariety,\n",
        "                Gender = gender,\n",
        "                Duration = duration,\n",
        "                Proficiency = prof,\n",
        "                Speaker = speaker) %>%\n",
        "  # clean word\n",
        "  dplyr::mutate(Word = str_remove_all(Word, \"\\\\W\")) %>%\n",
        "  dplyr::filter(hunspell_check(Word) == T) %>%\n",
        "  # remove \"shits\"\n",
        "  dplyr::filter(Word != \"shits\",\n",
        "                Word != \"stat\",\n",
        "                Word != \"whats\")\n",
        "# inspect\n",
        "head(bdat); names(table(bdat$Word))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvWoUsRuL4ob"
      },
      "source": [
        "## Check frequency of words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-CTuQCJL4oc"
      },
      "outputs": [],
      "source": [
        "# create a vector of words\n",
        "words <- names(table(bdat$Word))\n",
        "# load control corpus (ace, brown, lob files)\n",
        "controlc  <- base::readRDS(file = here::here(\"controlc.rda\"))\n",
        "# inspect\n",
        "str(controlc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZtqRJwtL4oe"
      },
      "source": [
        "extract word count of control corpus\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIOW8QCfL4of"
      },
      "outputs": [],
      "source": [
        "cleancontrolc <- controlc %>%\n",
        "  stringr::str_replace_all(\"<.*?>\", \" \") %>%\n",
        "  stringr::str_replace_all(\"[^[:alpha:] ]\", \" \") %>%\n",
        "  stringr::str_squish() %>%\n",
        "  quanteda::tokenize_fastestword() %>%\n",
        "  unlist() %>%\n",
        "  length()\n",
        "# inspect\n",
        "cleancontrolc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9SXV5onL4og"
      },
      "source": [
        "check how frequent the words are in the control corpus\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2mfMtpSL4og"
      },
      "outputs": [],
      "source": [
        "freqs <- sapply(words, function(x){\n",
        "  x <- stringr::str_count(controlc, paste0(\"\\\\W\", x, \"\\\\W\", sep = \"\", collapse = \"\"))\n",
        "})\n",
        "# convert into data frame\n",
        "freqsdf <- data.frame(names(freqs), freqs, cleancontrolc) %>%\n",
        "  dplyr::rename(Word = 1,\n",
        "                all = 3) %>%\n",
        "  dplyr::mutate(Frequency = log(freqs/all*1000)) %>%\n",
        "  dplyr::select(-freqs, -all)\n",
        "# inspect\n",
        "head(freqsdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdCJiuhwL4og"
      },
      "source": [
        "### Annotate word class\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPOTih0wL4og"
      },
      "outputs": [],
      "source": [
        "lexical <- c(\"bad\",  \"bed\", \"best\", \"big\", \"bit\", \"book\", \"books\", \"boost\", \"boots\", \"boss\", \"bought\", \"buds\", \"bus\", \"butts\", \"dad\", \"dead\", \"death\", \"debt\", \"debts\", \"desk\", \"dish\",  \"dust\", \"gap\", \"gas\",  \"good\",  \"guess\", \"head\", \"heads\",  \"hit\", \"hot\", \"key\", \"kid\", \"kids\", \"pass\", \"past\", \"pat\", \"path\", \"pub\", \"pubs\", \"push\", \"sad\", \"said\", \"sat\", \"says\", \"seat\", \"seats\", \"see\", \"seep\", \"sees\", \"set\", \"sets\",  \"shits\", \"shoes\", \"shop\", \"shops\", \"shut\", \"sit\", \"skip\",  \"speak\", \"spots\", \"stat\", \"step\", \"steps\", \"stop\", \"stops\", \"stud\", \"suit\", \"task\", \"tasks\", \"tea\", \"teeth\", \"test\", \"tests\", \"took\", \"top\", \"tough\", \"two\", \"wash\", \"ways\",  \"weak\", \"weed\", \"week\",  \"wish\",  \"wood\")\n",
        "bdat <- bdat %>%\n",
        "  dplyr::mutate(WordClass = ifelse(Word %in% lexical, \"lexical\", \"grammatical\"),\n",
        "                Word = as.vector(Word))\n",
        "bdat <- left_join(bdat, freqsdf, by = \"Word\") %>%\n",
        "  dplyr::mutate(vowel = stringr::str_remove_all(vowel, \"ː\"))\n",
        "# inspect\n",
        "table(bdat$WordClass); head(bdat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KXuYUzxL4oh"
      },
      "source": [
        "### Check durations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECcESRTDL4oh"
      },
      "outputs": [],
      "source": [
        "bdat %>%\n",
        "  ggplot(aes(x = vowel, y = Duration)) +\n",
        "  geom_boxplot()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzb7g9y_L4oh"
      },
      "source": [
        "Remove items with exaggerated duration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFku9zRpL4oh"
      },
      "outputs": [],
      "source": [
        "nrow(bdat)\n",
        "bdat <- bdat  %>%\n",
        "  # remove rare words\n",
        "  dplyr::group_by(type, Word) %>%\n",
        "  dplyr::mutate(freq = n()) %>%\n",
        "  dplyr::ungroup()\n",
        "# harmonize words\n",
        "nnwords <- bdat %>%\n",
        "  dplyr::filter(type == \"CHN\") %>%\n",
        "  dplyr::group_by(Word) %>%\n",
        "  dplyr::summarise(Freq = n()) %>%\n",
        "  dplyr::pull(Word)\n",
        "\n",
        "# remove rare vowels\n",
        "bdat <- bdat %>%\n",
        "  dplyr::group_by(vowel) %>%\n",
        "  dplyr::mutate(fr = n()) %>%\n",
        "  dplyr::filter(fr > 100) %>%\n",
        "  dplyr::select(-fr) %>%\n",
        "  dplyr::ungroup()\n",
        "# inspect\n",
        "str(bdat); nrow(bdat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utMg_3HcL4oi"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEYnb0AeL4oi"
      },
      "outputs": [],
      "source": [
        "bdat %>%\n",
        "  ggplot(aes(x = vowel, y = Duration)) +\n",
        "  geom_boxplot()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l-ovufLL4oi"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z4jtgdSL4oi"
      },
      "outputs": [],
      "source": [
        "tb2 <- bdat %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::mutate(Age = dplyr::case_when(Age < 30 ~ \"18-29\",\n",
        "                                       Age < 40 ~ \"30-39\",\n",
        "                                       Age < 50 ~ \"40-49\",\n",
        "                                       Age > 49 ~ \"50+\",\n",
        "                                       TRUE ~ \"unknown\")) %>%\n",
        "  dplyr::group_by(type, Gender, Age) %>%\n",
        "  dplyr::summarise(speakers = length(table(Speaker))) %>%\n",
        "  tidyr::spread(Age, speakers) %>%\n",
        "  dplyr::ungroup()  %>%\n",
        "  adorn_totals(\"row\")%>%\n",
        "  adorn_totals(\"col\")\n",
        "# inspect\n",
        "tb2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1aHdcqeL4oj"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKfkqxuDL4oj"
      },
      "outputs": [],
      "source": [
        "bdat <- bdat %>%\n",
        "  dplyr::mutate(F1 = as.vector(scale(F1)),\n",
        "                F2 = as.vector(scale(F2)),\n",
        "                Duration = as.vector(scale(Duration)),\n",
        "                Age = as.vector(scale(Age)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTmDYUFhL4oj"
      },
      "source": [
        "## Split data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK3cGtgTL4oj"
      },
      "outputs": [],
      "source": [
        "nsd <- bdat %>%\n",
        "  dplyr::filter(type == \"ENS\") %>%\n",
        "  dplyr::select(-type, -Proficiency, -Speaker, -file)  %>%\n",
        "  dplyr::mutate(Word = ifelse(Word %in% nnwords, Word, \"other\"))%>%\n",
        "  dplyr::mutate_if(is.character, factor)\n",
        "# inspect\n",
        "head(nsd); str(nsd)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IEQpci9L4oj"
      },
      "source": [
        "Remove impossible variables (too many levels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GFDCIHfL4oj"
      },
      "outputs": [],
      "source": [
        "nrow(nsd)\n",
        "nsd <- nsd %>%\n",
        "  dplyr::select(-fspeaker)\n",
        "str(nsd); nrow(nsd)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk8yYOVYL4ok"
      },
      "source": [
        "### Split native speaker data into test and training set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zlrsFgRL4ok"
      },
      "outputs": [],
      "source": [
        "# add id to data\n",
        "nsd <- nsd %>% dplyr::mutate(id = 1:nrow(.))\n",
        "# create training set (70%)\n",
        "nsdtrain <- nsd %>% dplyr::sample_frac(0.70)\n",
        "# create test set (30%)\n",
        "nsdtest  <- dplyr::anti_join(nsd, nsdtrain, by = 'id') %>%\n",
        "  dplyr::select(-id)\n",
        "# remove id column\n",
        "nsdtrain <- nsdtrain %>% dplyr::select(-id)\n",
        "# inspect\n",
        "head(nsdtrain); head(nsdtest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHfbUeSkL4ok"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01udUvEVL4ok"
      },
      "outputs": [],
      "source": [
        "nnsd <- bdat %>%\n",
        "  dplyr::filter(type != \"ENS\") %>%\n",
        "  droplevels() %>%\n",
        "  dplyr::select(-file, -type, -fspeaker)\n",
        "# save predictors associated with proficiency for later\n",
        "pred_nns <- nnsd %>% dplyr::select(Speaker, Proficiency)\n",
        "# remove proficiency variables (for now)\n",
        "nnsd <- nnsd %>%\n",
        "  dplyr::select(-Proficiency, -Speaker)\n",
        "# inspect data\n",
        "head(nnsd); str(nnsd)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FjhWx9TL4ok"
      },
      "source": [
        "## Harmonize words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZXGm3CWL4ok"
      },
      "outputs": [],
      "source": [
        "nswords <- nsdtrain %>%\n",
        "  dplyr::group_by(Word) %>%\n",
        "  dplyr::summarise(Freq = n()) %>%\n",
        "  dplyr::pull(Word)\n",
        "nnsd <- nnsd %>%\n",
        "  dplyr::mutate(Word = ifelse(Word %in% nswords, Word, \"other\")) %>%\n",
        "  dplyr::mutate_if(is.character, factor)\n",
        "# inspect\n",
        "str(nnsd); str(nsdtrain); nswords\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaKjeX75L4ol"
      },
      "source": [
        "Remove superfluous predictors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyXqjweEL4ol"
      },
      "outputs": [],
      "source": [
        "# nnsd\n",
        "nnsd <- nnsd %>%\n",
        "  dplyr::select(-id, -Vowel, -TargetVariety, -edist, -barkF1, -barkF2, -lobF1,\n",
        "                -lobF2, -normF1, -normF2, -cF1, -cF2, -ED, -WordType, -freq) %>%\n",
        "  dplyr::rename(Vowel = vowel)\n",
        "# nsdtrain\n",
        "nsdtrain <- nsdtrain %>%\n",
        "  dplyr::select(-Vowel, -TargetVariety, -edist, -barkF1, -barkF2, -lobF1,\n",
        "                -lobF2, -normF1, -normF2, -cF1, -cF2, -ED, -WordType, -freq) %>%\n",
        "  dplyr::rename(Vowel = vowel)\n",
        "# nsdtest\n",
        "nsdtest <- nsdtest %>%\n",
        "  dplyr::select(-Vowel, -TargetVariety, -edist, -barkF1, -barkF2, -lobF1,\n",
        "                -lobF2, -normF1, -normF2, -cF1, -cF2, -ED, -WordType, -freq) %>%\n",
        "  dplyr::rename(Vowel = vowel)\n",
        "# inspect\n",
        "colnames(nnsd); colnames(nsdtrain); colnames(nsdtest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxpxn7ZuL4om"
      },
      "source": [
        "## MuPDARF\n",
        "\n",
        "Prepare data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_y_38DPLL4om"
      },
      "outputs": [],
      "source": [
        "wrds1 <- names(table(nsdtest$Word))[table(nsdtest$Word) > 0]\n",
        "wrds2 <- names(table(nsdtrain$Word))[table(nsdtrain$Word) > 0]\n",
        "wrds3 <- names(table(nnsd$Word))[table(nnsd$Word) > 0]\n",
        "wrds <- Reduce(intersect, list(wrds1, wrds2, wrds3))\n",
        "# apply to data sets\n",
        "nsdtest <- nsdtest %>%\n",
        "  dplyr::mutate(Word = ifelse(Word %in% wrds, as.character(Word), \"other\"))\n",
        "nsdtrain <- nsdtrain %>%\n",
        "  dplyr::mutate(Word = ifelse(Word %in% wrds, as.character(Word), \"other\"))\n",
        "nnsd <- nnsd %>%\n",
        "  dplyr::mutate(Word = ifelse(Word %in% wrds, as.character(Word), \"other\"))\n",
        "# inspect\n",
        "wrds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4YWG5xNL4om"
      },
      "source": [
        "### RF NS\n",
        "\n",
        "Now, we perform a random forest analysis of the native speaker data.\n",
        "\n",
        "\n",
        "Now, we perform a random forest analysis of the native speaker data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slZoQpG-L4om"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "set.seed(sum(utf8ToInt(\"RFNS\")))\n",
        "nsrf <- randomForest(Vowel ~ ., data=nsdtrain, ntree=1000, proximity=TRUE, importance=TRUE)\n",
        "# inspect rf results\n",
        "nsrf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2SVWXuhL4om"
      },
      "source": [
        "visualise misclassification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyDhaPEIL4om"
      },
      "outputs": [],
      "source": [
        "nmc <- nsrf$confusion[, -7] %>%\n",
        "  as.data.frame() %>%\n",
        "  dplyr::mutate(Vowel = rownames(.)) %>%\n",
        "  tidyr::gather(NativeChoice, freq, æ:ʊ) %>%\n",
        "  dplyr::mutate_if(is.character, factor) %>%\n",
        "  dplyr::mutate(freq = ifelse(freq == 0, NA, freq))\n",
        "\n",
        "ggplot(nmc, aes(x=Vowel, y=NativeChoice, color=freq, size=freq, label=freq)) +\n",
        "  #geom_tile()+\n",
        "  geom_point() +\n",
        "  geom_text(size = 3, hjust=1.5, color = \"gray20\")+\n",
        "  scale_color_gradient(high=\"darkblue\", low=\"gray90\") +\n",
        "  labs(x = \"Observed vowel (ENS)\", y = \"Predicted vowel\\n(based on ENS trained model)\", title = \"(Mis-)Classification of vowels among ENS\") +\n",
        "  theme_bw()+\n",
        "  theme(legend.position = \"none\",\n",
        "        panel.grid.major = element_blank(),\n",
        "        panel.grid.minor = element_blank())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXsCxO5GL4om"
      },
      "source": [
        "Next, we plot the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7NQKQ4wL4om"
      },
      "outputs": [],
      "source": [
        "plot(nsrf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWX5u0SdL4om"
      },
      "source": [
        "Now, we plot the out-of-bag error frequencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSAN996DL4om"
      },
      "outputs": [],
      "source": [
        "# plot new precision/error rate\n",
        "oob.error.data <- data.frame(\n",
        "  Trees = rep(1:nrow(nsrf$err.rate), times=ncol(nsrf$err.rate)),\n",
        "  Type = rep(dimnames(nsrf$err.rate)[[2]], each=nrow(nsrf$err.rate)),\n",
        "  Error = as.vector(unlist(nsrf$err.rate)))\n",
        "# visualise\n",
        "ggplot(data=oob.error.data, aes(x=Trees, y=Error)) +\n",
        "  geom_line(aes(color=Type, linetype = Type)) +\n",
        "  theme_bw()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C776BzTDL4on"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMl_yf1nL4on"
      },
      "outputs": [],
      "source": [
        "oob.error.data %>%\n",
        "  dplyr::filter(Type != \"OOB\") %>%\n",
        "  ggplot(aes(x=reorder(Type, -Error, mean), y= Error,  group = Type)) +\n",
        "  geom_boxplot(fill = \"lightgray\") +\n",
        "  coord_cartesian(ylim = c(0, 1)) +\n",
        "  theme_bw(base_size = 10) +\n",
        "  theme(axis.text.x = element_text(size=10),\n",
        "        axis.text.y = element_text(size=10, face=\"plain\")) +\n",
        "  labs(x = \"\", y = \"Error rate (%)\") +\n",
        "  scale_y_continuous(limits = c(0, 1),\n",
        "                     labels = seq(0, 100, 20),\n",
        "                     breaks = seq(0, 1, .2)) +\n",
        "  scale_color_manual(guide = FALSE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh9goCwiL4on"
      },
      "source": [
        "Now, we check the error rates and accuracy and also check how much the model performs better than a base-line model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlxpvCZ7L4oo"
      },
      "outputs": [],
      "source": [
        "# determine accuracy by prediction\n",
        "# prediction\n",
        "pnsrf <- predict(nsrf, nsdtest)\n",
        "# create confusion matrix\n",
        "confusionMatrix(pnsrf, nsdtest$Vowel)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thCWjrxFL4oo"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIIGINc4L4oo"
      },
      "outputs": [],
      "source": [
        "cmnsd <- confusionMatrix(pnsrf, nsdtest$Vowel)\n",
        "# calculate increase in prediction accuracy compared to base-line model\n",
        "cmnsd$overall[1]\n",
        "cmnsd$overall[5]\n",
        "\n",
        "cmnsd$overall[1]/cmnsd$overall[5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6uAMhY5L4oo"
      },
      "source": [
        "Now, we inspect which variables are important for the predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL5vgl2xL4oo"
      },
      "outputs": [],
      "source": [
        "impdat <- data.frame(\n",
        "  Measure = c(rep(\"Accuracy\", length(nsrf$importance[,\"MeanDecreaseAccuracy\"])),\n",
        "              rep(\"Gini\", length(nsrf$importance[,\"MeanDecreaseGini\"]))),\n",
        "  Label = rep(dimnames(nsrf$importance)[[1]], 2),\n",
        "  Value = c(nsrf$importance[,\"MeanDecreaseAccuracy\"], nsrf$importance[,\"MeanDecreaseGini\"]))\n",
        "# ordering\n",
        "impdat <- impdat %>%\n",
        "  dplyr::group_by(Measure) %>%\n",
        "  dplyr::mutate(NormMeasure = scale(Value))\n",
        "# inspect\n",
        "impdat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cnArAAvL4oo"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7mcy3EqL4oo"
      },
      "outputs": [],
      "source": [
        "impdat %>%\n",
        "  ggplot(aes(x = reorder(Label, NormMeasure), y = Value)) +\n",
        "  geom_point() +\n",
        "  facet_grid(~Measure, scales=\"free\") +\n",
        "  coord_flip() +\n",
        "  theme_bw() +\n",
        "  labs(x = \"\", y = \"\", title = \"Importance of Predictors in Random Forest\\n (measured as mean decrease if perdictor is absent)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZKTw6aLL4op"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqVGrc41L4op"
      },
      "outputs": [],
      "source": [
        "errors_nsd <- nsdtest %>%\n",
        "  dplyr::mutate(Prediction = predict(nsrf, nsdtest),\n",
        "                Error = ifelse(Vowel == Prediction, 0, 1)) %>%\n",
        "  dplyr::group_by(Vowel) %>%\n",
        "  dplyr::summarise(all = n(),\n",
        "                   errors = sum(Error),\n",
        "                   Percent = round(errors/all*100, 1)) %>%\n",
        "  dplyr::ungroup() %>%\n",
        "    dplyr::mutate(Vowel = as.character(Vowel),\n",
        "                  Type = \"ENS\") %>%\n",
        "  dplyr::select(-all, -errors)\n",
        "# inspect\n",
        "head(errors_nsd)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBNaOSHeL4op"
      },
      "source": [
        "### RF NNS\n",
        "\n",
        "Now, we use the random forest analysis of the native speakers to predict what vowel a native speaker would have produced in the  non-native speaker contexts In a first step, we extract only non-native speaker data.\n",
        "\n",
        "Next, we use the random forest analysis of the native speakers to predict what vowel a native speaker would have used.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0rwKMwbL4op"
      },
      "outputs": [],
      "source": [
        "# extract prediction for training data\n",
        "pnns <- predict(nsrf, nnsd)\n",
        "# inspect predictions\n",
        "head(pnns); head(nnsd$Vowel)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHoSzmtcL4op"
      },
      "source": [
        "Now, we create a confusion matrix to check the accuracy of the prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZkJN4wZL4oq"
      },
      "outputs": [],
      "source": [
        "confusionMatrix(pnns, nnsd$Vowel)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO_ivxNLL4oq"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkGmLQw-L4oq"
      },
      "outputs": [],
      "source": [
        "cmnsd <- confusionMatrix(pnns, nnsd$Vowel)\n",
        "# calculate increase in prediction accuracy compared to base-line model\n",
        "cmnsd$overall[1]\n",
        "cmnsd$overall[5]\n",
        "\n",
        "cmnsd$overall[1]/cmnsd$overall[5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOeB4CynL4oq"
      },
      "source": [
        "The prediction accuracy increases by `r round(cmnsd$overall[1]/cmnsd$overall[5]*100, 1)` percent if use use our model compared to a no information model.\n",
        "\n",
        "\n",
        "Next, we add the difference between predictions and observed amplification to the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZSJbGWqL4oq"
      },
      "outputs": [],
      "source": [
        "# add native choice prediction to data\n",
        "nnsd <- nnsd %>%\n",
        "  dplyr::mutate(NativeChoice = as.vector(pnns),\n",
        "                NativeChoice = as.factor(NativeChoice)) %>%\n",
        "  # code if choice of nns is nativelike or not\n",
        "  dplyr::mutate(Vowel = as.character(Vowel),\n",
        "                NativeChoice = as.character(NativeChoice),\n",
        "                NonNativeLike = ifelse(Vowel == NativeChoice, 0, 1))\n",
        "\n",
        "# inspect new data\n",
        "head(nnsd)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb1K0lj3L4oq"
      },
      "source": [
        "### Inspect words where the vowels are wrong\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL5Z7D6VL4oq"
      },
      "outputs": [],
      "source": [
        "errors_words <- nnsd %>%\n",
        "  dplyr::filter(NonNativeLike == 1) %>%\n",
        "  dplyr::select(Word, Vowel, NativeChoice) %>%\n",
        "  dplyr::group_by(Word, Vowel, NativeChoice) %>%\n",
        "  dplyr::summarise(freq = n()) %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::arrange(-freq)\n",
        "# inspect\n",
        "errors_words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw-7hkS0L4or"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm8Xz7T9L4os"
      },
      "outputs": [],
      "source": [
        "table(errors_words$Word, errors_words$NativeChoice)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66fy3vLuL4os"
      },
      "source": [
        "visualise misclassification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4ENBbQ-L4os"
      },
      "outputs": [],
      "source": [
        "pmc <- nnsd %>%\n",
        "  dplyr::select(Vowel, NativeChoice) %>%\n",
        "  dplyr::mutate_if(is.character, factor) %>%\n",
        "  dplyr::group_by(Vowel, NativeChoice) %>%\n",
        "  dplyr::summarise(freq = n())\n",
        "\n",
        "ggplot(pmc, aes(x=Vowel, y=NativeChoice, color=freq, size=freq, label=freq)) +\n",
        "  #geom_tile()+\n",
        "  geom_point() +\n",
        "  geom_text(size = 3, hjust=1.5, color = \"gray20\")+\n",
        "  scale_color_gradient(high=\"darkblue\", low=\"gray90\") +\n",
        "  labs(x = \"Observed vowel (CHN)\", y = \"Predicted vowel\\n(based on ENS trained model)\", title = \"(Mis-)Classification of vowels among CHN\") +\n",
        "  theme_bw()+\n",
        "  theme(legend.position = \"none\",\n",
        "        panel.grid.major = element_blank(),\n",
        "        panel.grid.minor = element_blank())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3SOKp00L4os"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFMdCfO2L4os"
      },
      "outputs": [],
      "source": [
        "errors_nnsd <- nnsd %>%\n",
        "  dplyr::group_by(Vowel, NonNativeLike) %>%\n",
        "  dplyr::summarise(freq = n()) %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::group_by(Vowel) %>%\n",
        "  dplyr::summarise(all = sum(freq),\n",
        "                   Percent = round(freq/all*100, 1),\n",
        "                   NonNativeLike = NonNativeLike) %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::filter(NonNativeLike == 1) %>%\n",
        "  dplyr::select(-all, -NonNativeLike) %>%\n",
        "  dplyr::mutate(Type = \"CHN\")\n",
        "# inspect\n",
        "head(errors_nnsd); errors_nsd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JizlavrfL4os"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHe6Zng0L4os"
      },
      "outputs": [],
      "source": [
        "dplyr::full_join(errors_nnsd, errors_nsd) %>%\n",
        "  dplyr::mutate_if(is.character, factor) %>%\n",
        "  dplyr::group_by(Vowel) %>%\n",
        "  dplyr::arrange(Vowel) %>%\n",
        "  dplyr::mutate(odr = ifelse(Type == \"ENS\", Percent, NA)) %>%\n",
        "  tidyr::fill(odr, .direction = \"updown\") %>%\n",
        "  dplyr::arrange(-odr) %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  ggplot(aes(x = reorder(Vowel, -odr), y = Percent, label = Percent, fill = Type, group = Type)) +\n",
        "  geom_bar(stat=\"identity\", position = position_dodge()) +\n",
        "  geom_text(aes(y = Percent+3), position = position_dodge(0.9), size = 2.5, color = \"grey10\") +\n",
        "  theme_bw() +\n",
        "  labs(x = \"\", y = \"Error rate (%)\") +\n",
        "  scale_fill_manual(values = c(\"gray50\", \"gray80\"),\n",
        "                    labels = c(\"L1 English speakers (ENS, test data)\", \"Chinese learners (CHN)\")) +\n",
        "  theme(legend.position = \"top\",\n",
        "        legend.title = element_text(\"\")) +\n",
        "  coord_cartesian(ylim = c(0, 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo4j4ypxL4os"
      },
      "source": [
        "## GLMM\n",
        "\n",
        "\n",
        "Now, we perform a regression analysis on then difference between native speakers and non-native speakers. We begin by creating fixed-effects intercept-only base-line models.\n",
        "\n",
        "prepare data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri5rJTfzL4ot"
      },
      "outputs": [],
      "source": [
        "# add proficiency variables\n",
        "rdat <- cbind(nnsd, pred_nns) %>%\n",
        "  dplyr::mutate(Proficiency = factor(Proficiency),\n",
        "                NonNativeLike = factor(NonNativeLike)) %>%\n",
        "  dplyr::group_by(Word) %>%\n",
        "  dplyr::mutate(freq = n()) %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::mutate(Word = ifelse(freq > 12, as.character(Word), \"other\"),\n",
        "                F1 = round(F1, 0),\n",
        "                F2 = round(F2, 0),\n",
        "                Duration = round(Duration, 3)) %>%\n",
        "  dplyr::mutate_if(is.character, factor) %>%\n",
        "  dplyr::select(-freq, -NativeChoice)\n",
        "# inspect\n",
        "head(rdat); str(rdat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CeyqQpbL4ot"
      },
      "source": [
        "### Modeling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEml7EVzL4ot"
      },
      "outputs": [],
      "source": [
        "# set options\n",
        "options(contrasts = c(\"contr.treatment\", \"contr.poly\"))\n",
        "nnsd.dist <- datadist(rdat)\n",
        "options(datadist = \"nnsd.dist\")\n",
        "# generate initial minimal regression model\n",
        "# baseline model glm\n",
        "m0 = glmer(NonNativeLike ~ (1 | Word) + (1 | Speaker), family = binomial, data = rdat)\n",
        "# inspect results\n",
        "summary(m0)\n",
        "# inspect\n",
        "sjPlot::tab_model(m0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtwweBs6L4ot"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmHWoIydL4ot"
      },
      "outputs": [],
      "source": [
        "r.squaredGLMM(m0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0S6gWMdL4ot"
      },
      "source": [
        "Model fitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QeXUYEaL4ot"
      },
      "outputs": [],
      "source": [
        "# wrapper function for linear mixed-models\n",
        "glmer.glmulti <- function(formula, data, random=\"\",...){\n",
        "  glmer(paste(deparse(formula),random), family = binomial,  data=data, control = glmerControl(optimizer=\"bobyqa\"), ...)\n",
        "}\n",
        "# define formular\n",
        "form_glmulti = as.formula(paste(\"NonNativeLike ~  Vowel + Duration +  Gender + Proficiency + WordClass + Frequency\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSSG012aL4ou"
      },
      "source": [
        "Extract best 5 models.\n",
        "\n",
        "***\n",
        "\n",
        "> WARNING: DO NOT EXECUTE THE FOLLOWING CODE CHUNK! It requires Java and takes multiple hours!\n",
        "\n",
        "***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XRdwxTvL4ou"
      },
      "outputs": [],
      "source": [
        "#library(glmulti)\n",
        "# multi selection for glmer\n",
        "#mfit <- glmulti(form_glmulti, random=\"+(1|Word)+(1|Speaker)\",\n",
        "#                data = rdat, method = \"h\", fitfunc = glmer.glmulti,  includeobjects = T,\n",
        "#                crit = \"aic\", intercept = TRUE, marginality = FALSE, level = 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIESgeEPL4ou"
      },
      "source": [
        "After 2000 models:\n",
        "Best model: NonNativeLike~1+Vowel+Frequency+Vowel:Frequency+WordClass:Frequency\n",
        "Crit= 1083.85798375276\n",
        "Mean crit= 1085.21585106472\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4IORg3oL4ou"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "set.seed(sum(utf8ToInt(\"GLMER\")))\n",
        "# generate final model (include main effects)\n",
        "mf <- glmer(NonNativeLike ~ (1 | Word)  + (1 | Speaker) +\n",
        "              Vowel+Frequency+Vowel:Frequency+WordClass:Frequency,\n",
        "            family = binomial, data = rdat)\n",
        "# inspect\n",
        "sjPlot::tab_model(mf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4uq6HM9L4ou"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGlll5EbL4ou"
      },
      "outputs": [],
      "source": [
        "r.squaredGLMM(mf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOmPg-y0L4ou"
      },
      "source": [
        "check for multicollinearity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l3FoBrhL4ou"
      },
      "outputs": [],
      "source": [
        "car::vif(mf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbo_6SiQL4ov"
      },
      "source": [
        "check effects\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "030jjm_xL4ov"
      },
      "outputs": [],
      "source": [
        "p <- plot_model(mf, type = \"re\", sort.est = TRUE, grid = FALSE)\n",
        "p[[1]] +\n",
        "  theme_bw() +\n",
        "  theme(axis.text.y = element_text(size=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu6I5ThRL4ov"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvkjdOKeL4ov"
      },
      "outputs": [],
      "source": [
        "p[[2]] +\n",
        "  theme_bw()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Zc-JhqL4ow"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juF4pDokL4ow"
      },
      "outputs": [],
      "source": [
        "sjPlot::plot_model(mf, type = \"pred\",\n",
        "                   terms = c(\"WordClass\", \"Vowel\"),\n",
        "                   se = FALSE,\n",
        "                   ci.lvl = FALSE,\n",
        "                   colors = viridis(6)) +\n",
        "  theme_bw() +\n",
        "  labs(title = \"\", y = \"Predicted percent non-target-like production\",\n",
        "       x = \"Word class\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qw9ZNSVL4ox"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQSC71oYL4ox"
      },
      "outputs": [],
      "source": [
        "sjPlot::plot_model(mf,\n",
        "                   type = \"pred\",\n",
        "                   terms = c(\"Frequency\",\"Vowel\"),\n",
        "                   se = FALSE,\n",
        "                   ci.lvl = FALSE,\n",
        "                   colors = viridis(6)) +\n",
        "  ggplot2::annotate(geom = \"text\", label = \"/æ/\", x = 3.5, y = .93, color = viridis(6)[1], size = 4.5) +\n",
        "  ggplot2::annotate(geom = \"text\", label = \"/ɪ/\", x = 3.5, y = .98, color = viridis(6)[4], size = 4.5) +\n",
        "  ggplot2::annotate(geom = \"text\", label = \"/u/\", x = -9.5, y = 1, color = viridis(6)[5], size = 4.5) +\n",
        "  ggplot2::annotate(geom = \"text\", label = \"/ʊ/\", x = -9.5, y = .18, color = viridis(6)[6], size = 4.5) +\n",
        "  theme_bw()  +\n",
        "  labs(title = \"\", y = \"Predicted percent non-target-like production\",\n",
        "       x = \"Frequency (logged, centered, scaled)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0aTXWXoL4ox"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ8mCYygL4oy"
      },
      "outputs": [],
      "source": [
        "p <- sjPlot::plot_model(mf,\n",
        "                   type = \"pred\",\n",
        "                   terms = c(\"Vowel\"),\n",
        "                   se = FALSE,\n",
        "                   ci.lvl = FALSE)\n",
        "mf_dat <- p$data$predicted %>%\n",
        "  as.data.frame() %>%\n",
        "  dplyr::mutate(Vowel = names(table(rdat$Vowel))) %>%\n",
        "  dplyr::rename(Prediction = 1) %>%\n",
        "  dplyr::mutate(Prediction = Prediction*100)\n",
        "mf_dat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HmcfjucL4oy"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5a5sinaL4oy"
      },
      "outputs": [],
      "source": [
        "mf_dat %>%\n",
        "  ggplot(aes(x = reorder(Vowel, -Prediction, mean), y = Prediction, shape = Vowel, color = Vowel, label = round(Prediction, 3))) +\n",
        "  geom_point(size = 5) +\n",
        "  geom_text(size = 3, hjust=-0.5) +\n",
        "  scale_shape_manual(values = names(table(mf_dat $Vowel))) +\n",
        "  scale_color_manual(values = viridis(6)) +\n",
        "  labs(y =\"Predicted percent non-target-like production\",\n",
        "       x = \"\") +\n",
        "  theme_bw() +\n",
        "  theme(legend.position = \"none\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDiK0tSUL4oy"
      },
      "source": [
        "## Tabulation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlmLiXvBL4oy"
      },
      "outputs": [],
      "source": [
        "# save tables\n",
        "str(rdat)\n",
        "str(nsdtrain)\n",
        "str(nsdtest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blZ6__2yL4oy"
      },
      "source": [
        "## Overview of the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHKa-4KVL4oy"
      },
      "outputs": [],
      "source": [
        "tb1 <- bdat %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::group_by(type) %>%\n",
        "  dplyr::mutate(speakers = length(table(Speaker))) %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::group_by(type, vowel) %>%\n",
        "  dplyr::summarise(speakers = speakers,\n",
        "                   obs = n()) %>%\n",
        "  unique() %>%\n",
        "  tidyr::spread(vowel, obs) %>%\n",
        "  dplyr::ungroup()  %>%\n",
        "  adorn_totals(\"row\")%>%\n",
        "  adorn_totals(\"col\") %>%\n",
        "  dplyr::mutate(Total = Total-speakers)\n",
        "# inspect\n",
        "tb1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCX0H3wTL4oy"
      },
      "source": [
        "tabulate proficiency\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ouX4eU8L4oy"
      },
      "outputs": [],
      "source": [
        "tb3 <- bdat %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::filter(type == \"CHN\")%>%\n",
        "  dplyr::group_by(Proficiency, Gender) %>%\n",
        "  dplyr::summarise(speakers = length(table(Speaker))) %>%\n",
        "  tidyr::spread(Proficiency, speakers) %>%\n",
        "  dplyr::ungroup()  %>%\n",
        "  adorn_totals(\"row\")%>%\n",
        "  adorn_totals(\"col\")\n",
        "# inspect\n",
        "tb3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oQQl29pL4oz"
      },
      "source": [
        "tabulate gender and type\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkU8fSruL4oz"
      },
      "outputs": [],
      "source": [
        "tb4 <- bdat %>%\n",
        "  dplyr::ungroup() %>%\n",
        "  dplyr::group_by(Gender, type) %>%\n",
        "  dplyr::summarise(speakers = length(table(Speaker))) %>%\n",
        "  tidyr::spread(Gender, speakers) %>%\n",
        "  dplyr::ungroup()  %>%\n",
        "  adorn_totals(\"row\")%>%\n",
        "  adorn_totals(\"col\")\n",
        "# inspect\n",
        "tb4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YNrtKRqL4oz"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSdmNp56L4oz"
      },
      "outputs": [],
      "source": [
        "summary(bdat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMcgtzhwL4oz"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AocrxtbbL4oz"
      },
      "outputs": [],
      "source": [
        "summary(nnsd)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQvBgXByL4oz"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eKkDhymL4oz"
      },
      "outputs": [],
      "source": [
        "summary(rdat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHbwXDU5L4oz"
      },
      "source": [
        "## Citation & Session Info\n",
        "\n",
        "Schweinberger, Martin. 2024. An acoustic analysis of vowel production by L1-Chinese learners of English - Part 3: Statistical Analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDWJsBffL4o0"
      },
      "outputs": [],
      "source": [
        "sessionInfo()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": "",
    "kernelspec": {
      "display_name": "R",
      "langauge": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.4.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}